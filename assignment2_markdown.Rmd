---
title: "Assignment 2"
author: "B166247"
date: "3 3 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Problem 1
## (a)

```{r warning=FALSE}
#loading the required library
library(data.table)

#loading the files
lipids.dt <- data.table(read.delim("lipids.txt"))
classes.dt <- data.table(read.delim("lipid-classes.txt"))

#lipid classes can be found in the first column of lipids.dt
#Finding all lipids PC and assignment to new column lipid.class (42)
lipids.dt[grep("^[Pp]C", lipid.species), lipid.class := classes.dt[CE == "PC", Cholesterol.esters]]
#Finding all Cer (11)
lipids.dt[grep("^[Cc]er|CER", lipid.species), lipid.class := classes.dt[CE == "Cer", Cholesterol.esters]]
#Finding all DAG (16)
lipids.dt[grep("^[Dd]ag|DAG", lipid.species), lipid.class := classes.dt[CE == "DAG", Cholesterol.esters]]
#Finding all LPC (13)
lipids.dt[grep("^[Ll]pc|LPC", lipid.species), lipid.class := classes.dt[CE == "LPC", Cholesterol.esters]]
#Finding all LPE (3)
lipids.dt[grep("^[Ll]pe|LPE", lipid.species), lipid.class := classes.dt[CE == "LPE", Cholesterol.esters]]
#Finding all PE (25)
lipids.dt[grep("^[Pp]e|^PE", lipid.species), lipid.class := classes.dt[CE == "PE", Cholesterol.esters]]
#Finding all PS (8)
lipids.dt[grep("^[Pp]s|^PS", lipid.species), lipid.class := classes.dt[CE == "PS", Cholesterol.esters]]
#Finding all SM (0)
lipids.dt[grep("[Ss]m|SM", lipid.species)]
#Finding all TAG (147)
lipids.dt[grep("[Tt]ag|TAG", lipid.species), lipid.class := classes.dt[CE == "TAG", Cholesterol.esters]]

#it can be seen that 9 rows are still unoccupied (correspond to CE)
lipids.dt[is.na(lipid.class)]

```
After adding all classes provided in the classes.txt file, it can be seen that one class is missing and 9 rows with the abbreviation CE could not be annotated. Following the shorthand notation of lipids published by Liebisch et al. in 2013 CE corresponds to Cholesteryl ester (Liebisch et al., 2013). I added this class manually.
```{r}
#manual addition of Cholesteryl ester
lipids.dt[grep("\\b[C]e\\b|\\bCE\\b", lipid.species), lipid.class := "Cholesteryl ester"]
#test that all lipids have a class
stopifnot(!is.na(lipids.dt$lipid.class))

#count the number of entries corresponding to each class (one class missing only 8!)
lipids.dt[, .(count = .N), lipid.class]

```
## (b)
Since there are 9 lipid species in the table (including CE and exclusing SM), they are calculated as following:
```{r}
#calculate the Wald test (t-distributed)
lipids.dt[, "Wald.test(t.dist)":= round(((oddsratio-1)/se), 3)]

#calculate the degress of freedom
df <- 288-9-1

#calculate the p-value based on the t-distribution
lipids.dt[, "p.value.t" := signif(2*pt(abs(`Wald.test(t.dist)`), df, lower.tail = FALSE), 4)]

#calculate the p-value based on the normal distribution
results.dt <- lipids.dt[, "p.value.norm" := signif(2*pnorm(`Wald.test(t.dist)`, lower.tail = FALSE), 4)]

#checking the table
head(results.dt)
```
Present some evidence to justify if the normal approximation is acceptable in this instance. (ANSWER)

## (c)
```{r warning=FALSE}
holm.bonferroni <- function(results.dt, alpha){
  #copy and order the input dataframe
  order.dt <- results.dt[order(p.value.t),]
  
  #looping through all sorted entries
  for (row.idx in seq(1,nrow(order.dt))){
    #calculate the threshhold value for the row
    pcalc <- alpha/(276+1-row.idx)
    #cat(pcalc)
    #testing if the threshold is passed
    if (pcalc >= order.dt[row.idx, p.value.t]) {
      #threshold is not passed anymore and the loop breaks
      lastidx <- row.idx
      #cat(lastidx, "\n")
      #cat("This is the pcalc ", pcalc)
    } else {
      #nothting happens when the pcalc gets too large
    }
  }
  
  #returning the subset of the ordered table
  return(order.dt[1:lastidx])
}

```
## (d)
```{r warning=FALSE}
benjamini.hochberg <- function(results.dt, q){
  q <- 0.01
  #copy and order the input dataframe
  order.dt <- results.dt[order(p.value.t),]
  
  #looping through all sorted entries
  for (row.idx in seq(1,nrow(order.dt))){
    pcalc <- (row.idx/276)*q
    
    #testing if the threshold is valid
    if (pcalc > order.dt[row.idx, p.value.t]){
      #assigning the indeces that pass the threshold
      lastidx <- row.idx
      #cat(lastidx, "\n")
      #cat("This is the pcalc ", pcalc)
    } else {
      #pass as the threshold was passed
    }
    
  }
  
  #return the subset in ascending p value order
  return(order.dt[1:lastidx])
  
}

```
## (e)
```{r warning=FALSE}

#finding the subsets that are significant
sigholm <- holm.bonferroni(results.dt, 0.05)
sigben <- benjamini.hochberg(results.dt, 0.01)

#plot the volcano plot
plot(log(results.dt$oddsratio), -log10(results.dt$p.value.t), main = "Volcano Plot Lipid Species",
     xlab = "log Odds Ratio",
     ylab = "-log10(p-value)",
     col = ifelse(results.dt$p.value.t %in% c(sigholm$p.value.t, sigben$p.value.t),"blue", "black" ),
     pch = ifelse(results.dt$p.value.t %in% sigholm$p.value.t, 4, 18),
     cex=ifelse((results.dt$p.value.t %in% sigholm$p.value.t | results.dt$p.value.t %in% sigben$p.value.t), 1.3, 0.3))

#add legend
legend("topleft", c("Holm-Bon. < 5%", "Holm-Bon. ≥ 5%", "Ben.-Hoch. < 1%", "Ben.-Hoch. ≥ 1%"), 
       col = c("blue","black", "blue", "black"),
       lwd = c(3,1,5,1),
       lty = c(NA,NA,NA,NA),
       pch = c(4,18,18,18))

```

## (f)
```{r warning=FALSE}
#Lipid Species that are significant after family wise error rate of 0.05
holmlipid.dt <- holm.bonferroni(lipids.dt, 0.05)
holmlipid.dt
```

```{r warning=FALSE}
#Lipid Species significant after false recovery rate of 0.05
benjaminlipid.dt <- benjamini.hochberg(lipids.dt, 0.05)
benjaminlipid.dt

```

```{r warning=FALSE}
#finding the lipid species that are significant with either method
lipid.inter <- which(results.dt$lipid.species %in% intersect(holmlipid.dt$lipid.species, benjaminlipid.dt$lipid.species))
results.dt[lipid.inter]

```

# Problem 2
## (a)
```{r warning=FALSE}
#loading the required libraries
library(caret)
library(pROC)
library(glmnet)

#load the data set
wdbc2.dt <- fread("wdbc2.csv", stringsAsFactors = TRUE)

#setting the seed
set.seed(1)

#create the data particioning
train.idx <- createDataPartition(wdbc2.dt$diagnosis, p=0.7)$Resample1

#function from lab 4 to convert data tables into a matrix as expected by glmnet
prepare.glmnet <- function(data, formula=~ .) {
  ## create the design matrix to deal correctly with factor variables,
  ## without losing rows containing NAs
  old.opts <- options(na.action='na.pass')
  x <- model.matrix(formula, data)
  options(old.opts)
  ## remove the intercept column, as glmnet will add one by default
  x <- x[, -match("(Intercept)", colnames(x))]
  return(x)
}

#separate desig matrix from outcomes
ywdbc2.dt <- as.matrix(wdbc2.dt$diagnosis)
xwdbc2.dt <- prepare.glmnet(wdbc2.dt[, !"id"], ~ . -diagnosis )


#fit ridge regression model with cross validation
fit.ridge <- glmnet(xwdbc2.dt, ywdbc2.dt, family="binomial", alpha=0, subset = train.idx)
#fit regression with lasso penalty
fit.lasso <- glmnet(xwdbc2.dt, ywdbc2.dt, family="binomial", subset = train.idx)

#plotting coefficients for lambda regression
plot(fit.ridge, main="Ridge trajectories")
plot(fit.lasso, main="Lasso trajectories")

#learning by cross validation
fit.cv.ridge <- cv.glmnet(xwdbc2.dt, ywdbc2.dt, family="binomial", alpha=0, subset = train.idx)
fit.cv.lasso <- cv.glmnet(xwdbc2.dt, ywdbc2.dt, family="binomial", subset = train.idx)

#Plotting the trajectory of the coefficients
plot(fit.cv.ridge, main="Ridge")
plot(fit.cv.lasso, main="Lasso") 



```
## (b)

Optimal AUC is given when lambda is at its minimum, ergo the maximum of cvm is the AUC corresponding to the optimal lambda
```{r}
#lambda for ridge regression model
max(fit.cv.ridge$cvm)
#lambda for lasso regression model
max(fit.cv.lasso$cvm)


#AUC for best lambda for ridge regression
fit.cv.ridge$cvm[which(fit.cv.ridge$lambda == fit.cv.ridge$lambda.min)]
#AUC for best lambda for lasso regression
fit.cv.lasso$cvm[which(fit.cv.lasso$lambda == fit.cv.lasso$lambda.min)]



#AUC within 1 sd of the maximum
#lasso regression
fit.cv.lasso$cvm[which(fit.cv.lasso$lambda == fit.cv.lasso$lambda.1se)]


#ridge regression
fit.cv.ridge$cvm[which(fit.cv.ridge$lambda == fit.cv.ridge$lambda.1se)]

```
## (c)
```{r}

#data table for ridge regression
fit.ridge.dt <- data.table(model.lambda = signif(fit.cv.ridge$lambda,3),
                           model.size = fit.cv.ridge$nzero,
                           model.AUC = signif(fit.cv.ridge$cvm))

#data table for lasso regression
fit.lasso.dt <- data.table(model.lambda = signif(fit.cv.lasso$lambda,3),
                           model.size = fit.cv.lasso$nzero,
                           model.AUC = signif(fit.cv.lasso$cvm, 3))

#test on test data???


plot(fit.ridge.dt$model.lambda, fit.ridge.dt$model.AUC, 
     col = ifelse(fit.cv.ridge$cvm == max(fit.cv.ridge$cvm), "red", "black"))

plot(fit.lasso.dt$model.lambda, fit.lasso.dt$model.AUC,
     col = ifelse(fit.cv.lasso$cvm == max(fit.cv.lasso$cvm), "red", "black"))

```
## (d)

No specific model is specified so the assumption was made that a logistic regression model was meant.
```{r}
#import library
library(MASS)


#fit logistic regression model on same training data
fit.log <- glm(diagnosis ~ ., data = wdbc2.dt[, !"id"], family = "binomial", subset= train.idx )

#perform backward elimination
log.back <- stepAIC(fit.log, direction="back")

#required coefficients with their estimate
log.back$coefficients[-1] #excluding the intercept

length(log.back$coefficients[-1])

#HOW DO I STANDARDIZE THE COEFFICIENTS??????????
#multiply by standard deviation of their associative predictor (see lab 5)

```

## (e)
```{r}

#difining the null model
null.forward <- glm(diagnosis ~ 1, data=wdbc2.dt[, !"id"], family="binomial", subset = train.idx)

#performing forward selection
log.forward <- stepAIC(null.forward, scope=list(upper=fit.log), direction="forward")

#no coefficients were selected and then later removed

#final coefficients
log.forward$coefficients[-1]

length(log.forward$coefficients[-1])
#how to standardize the coefficients

#summary(log.forward)

```
## (f) 
The best method for evaluation between the two models would be a log-likelihood test. However, since the two models are not nested, i.e. the forward selection model is not a special case of the backward elimination model, a log-likelihood analysis cannot  be performed. (see: https://www.statisticshowto.com/likelihood-ratio-tests/)
Therefore, I decided to compare the models based on Pseudo R squared or McFadden's R squared which gives the ratio of log-likelihoods between the current model and the null model
```{r}

#null model has already been defined during forward selection : null.forward

#McFadden's R squared for forward selection
1-logLik(log.forward)/logLik(null.forward)

#McFadden's R squared for backward elimination
1-logLik(log.back)/logLik(null.back)



```
The backward model has a slightly better McFadden's score than the forward selection model. However, these differences are only minimal which might justify the selection of the coefficients selected during the forward selection model for future studies.

## (g)
```{r}
#making the test set
test <- wdbc2.dt[-train.idx]

#forward selection predicted probabilities (right)
pred.prob.forward <- predict(log.forward, newdata=wdbc2.dt[train.idx], type="response")

#AUC for forward selection
roc(wdbc2.dt$diagnosis[train.idx], pred.prob.forward, data=wdbc2.dt[-train.idx])$auc

#predicted probabilities for backward elimination
pred.prob.backward <- predict(log.back, newdata = wdbc2.dt[train.idx], type="response")

#AUC for backward elimination
roc(wdbc2.dt$diagnosis[train.idx], pred.prob.backward, data=wdbc2.dt[-train.idx, ])$auc

```
## (h)
Ridge Regression AUC
```{r}

# ridge regression
pred.prob.test.ridge <- predict(fit.cv.ridge, newx = xwdbc2.dt[-train.idx,], type = "response", s=fit.cv.ridge$lambda.1se)

roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.ridge, data=wdbc2.dt[train.idx])$auc

```
Lasso Regression AUC
```{r}
#lasso regression
pred.prob.test.lasso <- predict(fit.cv.lasso, newx = xwdbc2.dt[-train.idx,], type = "response", s=fit.cv.lasso$lambda.1se)

roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.lasso, data=wdbc2.dt[train.idx])$auc

```
Backward Elimination AUC
```{r}


#backward elimination

#predicted probabilities for backward elimination
pred.prob.test.backward <- predict(log.back, newdata = wdbc2.dt[-train.idx], type="response")

#AUC for backward elimination
roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.backward, data=wdbc2.dt[train.idx])$auc

```
Forward Selection AUC
```{r}

#forward selection

#forward selection predicted probabilities (right)
pred.prob.test.forward <- predict(log.forward, newdata=wdbc2.dt[-train.idx], type="response")

#AUC for forward selection
roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.forward, data=wdbc2.dt[train.idx])$auc


```

Plotting the test AUC.
```{r}
#plotting the test AUC's
roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.forward, data=wdbc2.dt[train.idx],lagacy.axes=TRUE, plot = TRUE, lwd=1, main="Plot of Test AUC's", asp=NA)

roc(wdbc2.dt$diagnosis[-train.idx], pred.prob.test.backward, data=wdbc2.dt[train.idx], plot = TRUE, add=TRUE, col="orange", lwd=1)

roc(wdbc2.dt$diagnosis[-train.idx], as.vector(pred.prob.test.lasso), data=wdbc2.dt[train.idx], plot = TRUE, add=TRUE, col="red", lwd=1)

roc(wdbc2.dt$diagnosis[-train.idx], as.vector(pred.prob.test.ridge), data=wdbc2.dt[train.idx], plot=TRUE, add=TRUE, col="blue", lwd=1)

legend("bottomright", 
       c("Forward Elimination", "Backward Elimination", "Lasso Regression", "Ridge Regression"),
       fill = c("black", "orange", "red", "blue"))


```
Coparison between training and test AUC's:\n
\n
Ridge Regression:\n
Training: 0.4345539\n
Testing: 0.9895\n
The training AUC is significantly smaller than the the testing AUC which is expected since ridge regression introduces a small bias to not overfit the model on the training set. Therefore, this behaviour is normal and expected.

\n
Lasso Regression:\n
Training: 0.4504536\n
Testing: 0.9915\n
Similarly to the ridge regression, the lasso regression introduces a small bias to fit the test set better. Therefore, the training AUC is much greater than the test AUC. 
\n

Backward Elimination:\n
Training: 0.9717\n
Testing: 0.9855\n
Even though this model does not overfit the data (since Training AUC < Testing AUC), the general performance compared to the other three models is lower. It seems that the elminiation of coefficients slightly adds to the performance of the model. This is in contrast to the McFadden R square test performed in part (f) showing that the McFadden's score is not a good way of comparing the forward and backward model.

\n

Forward Elimination:\n
Training: 0.9891\n
Testing:0.9911\n
Similarly to the backward elimination model, the model is not overfit since the AUC increases from training to testing. 

#Problem 3

## (a)

```{r}

#read in the data table
gdm.dt <- data.table(read.delim("GDM.raw.txt"))


#separating the rsIDs and coded allele counts
colnames.list <- colnames(gdm.dt[, !c("ID", "sex", "pheno")])
snp.allele.dt <- as.data.table(matrix(unlist(lapply(colnames.list, function(x){strsplit(x,"_")})), ncol=2, byrow = TRUE))
colnames(snp.allele.dt)<- c("rsID","ref.allele")
snp.allele.dt[,coded.allele:=colnames(gdm.dt[, !c("ID", "sex", "pheno")])]
 

#impute to the mean
for (SNP.ref in colnames(gdm.dt[, !c("ID", "sex", "pheno")])) {
  #find missing values
  na.idx <- which(is.na(gdm.dt[[SNP.ref]])==TRUE)
  #assigning the mean
  gdm.dt[[SNP.ref]][na.idx] <- round(mean(gdm.dt[[SNP.ref]], na.rm = TRUE))
}



```
## (b)
```{r}


univ.glm.test <- function(x,y, order=FALSE){
  #x is a data table
  #y is a binary outcome vector
  
  stopifnot(nrow(x)==length(y))
  
  #output.dt <- data.table(SNP.name = NA, reg.coeff = NA, odds.ratio = NA, sd = NA, p.value = NA)
  
  SNP.names.vect <- c()
  slope.vect <- c()
  odds.ratio.vect <- c()
  sd.vect <- c()
  p.value.vect <- c()
  
  for (col in colnames(x)){
    #appending the column name
    SNP.names.vect <- c(SNP.names.vect, col)
    
    #reformatting the column of the dataframe to fit a model
    x.vect <- as.vector(unlist(x[[col]]))
    #fitting the model
    model <- glm(y ~ x.vect, family="binomial")
    
    #adding coefficient to the prepared vectors
    slope.vect <- c(slope.vect, summary(model)$coefficients[2])
    
    #adding the odds ratio
    odds.ratio.vect <- c(odds.ratio.vect, exp(summary(model)$coefficients[2]))
    
    #adding the standard error
    sd.vect <- c(sd.vect, summary(model)$coefficients[4])
    
    #adding the p-value
    p.value.vect <- c(p.value.vect ,summary(model)$coefficients[8])
    
    #constructing the output dataframe
    output.dt <- data.table(SNP.name = SNP.names.vect, reg.coeff = slope.vect, odds.ratio = odds.ratio.vect, 
                            sd = sd.vect, p.value = p.value.vect)
    
  }
  
  if (order==TRUE){
    setorder(output.dt, p.value)
  }
  
  return(output.dt)
}
```
## (c)
```{r}
#removing ID, sex and phenotype from the data table to prepare for SNP model
proc.gdm.dt <- gdm.dt[,!c("ID", "sex", "pheno")]
pheno.vect <- gdm.dt$pheno
ordered.bol <- TRUE

#run the SNP association study
modeled.snp.dt <- univ.glm.test(proc.gdm.dt, pheno.vect, ordered.bol)

#only select significant SNP loci
sig.outcome.dt <- modeled.snp.dt[ which(modeled.snp.dt[,p.value< 5e-2]==TRUE)]

#finding the most protective coefficient
sig.outcome.dt[,.SD[which.min(reg.coeff)]]

#95% confidence interval
beta <- sig.outcome.dt[,.SD[which.min(reg.coeff)]]$reg.coeff
se.beta <- sig.outcome.dt[,.SD[which.min(reg.coeff)]]$sd
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)

#99% confidence interval
round(exp(beta + 2.58 * se.beta * c(-1, 1)), 3)


#summary statistics of coefficient with biggest risk factor
sig.outcome.dt[,.SD[which.max(reg.coeff)]]

#95% confidence interval
beta2 <- sig.outcome.dt[,.SD[which.max(reg.coeff)]]$reg.coeff
se.beta2 <- sig.outcome.dt[,.SD[which.max(reg.coeff)]]$sd
round(exp(beta2 + 1.96 * se.beta2 * c(-1, 1)), 3)

#99% confidence interval
round(exp(beta2 + 2.58 * se.beta2 * c(-1, 1)), 3)


```
## (d)
```{r}

#read in the data table
annot.gdm.dt <- data.table(read.delim("GDM.annot.txt"))

#merge the modeled.snp.dt with allele names
gwas.prelim.dt <- merge(modeled.snp.dt, snp.allele.dt, by.x = "SNP.name", by.y = "coded.allele")
#merge the remaining two tables
gwas.dt <- merge(gwas.prelim.dt, annot.gdm.dt, by.x = "rsID", by.y = "snp")


#filtering hit alleles
hit.alleles <- gwas.dt[which(gwas.dt[,p.value<10e-4]==TRUE)]

  
#report SNP names, effect allele, chromosome number,gene name
hit.alleles[, c("SNP.name", "reg.coeff", "chrom", "gene")]


#function that takes in a rsID, a data table with required fields and a full data table returns the genes within 1MB
#this function is not self dependent, however the best option to implement this problem
genes.finder <- function(hits, hit.alleles, gwas.dt){
  pos.hit <- hit.alleles[rsID==hits,pos]
  chrom.hit <- hit.alleles[rsID==hits, chrom]
  max.gen.pos <- pos.hit -1000000
  min.gen.pos <- pos.hit + 1000000
  chrom.alleles <- which(gwas.dt[ ,chrom == chrom.hit & (pos> max.gen.pos & pos<min.gen.pos)])
  return(unique(gwas.dt[which(gwas.dt[ ,chrom == chrom.hit & (pos> max.gen.pos)])]$gene))
}

#there are 7 hits, however only the first, second and fourth are unique
genes.finder(hit.alleles$rsID[1], hit.alleles, gwas.dt)

genes.finder(hit.alleles$rsID[2], hit.alleles, gwas.dt)

genes.finder(hit.alleles$rsID[4], hit.alleles, gwas.dt)

```
## (e)
```{r}

#order the gwas table by SNP names in gdm columns
gwas.dt<- gwas.dt[order(match(SNP.name, colnames(gdm.dt)[-c(1,2,3)]))]

#ordering of SNPs
stopifnot(colnames(gdm.dt)[-c(1,2,3)] == gwas.dt$SNP.name)

#p.value < 10e-4
hit4 <- gwas.dt[p.value < 1e-4]
#columns of original table which come up as gwas significant
gdm.sig4.dt <- gdm.dt[, .SD, .SDcols = hit4$SNP.name]
#calculating the weighted score
weighted.score4.gwas <- as.matrix(gdm.sig4.dt) %*% hit4$reg.coeff
#adding the vector to the original data table
gdm.dt[, weighted4.scores := weighted.score4.gwas]
#outcome vector
outcome <- gdm.dt$pheno
#x weighted scores
x.weight4 <- gdm.dt$weighted4.scores
#fit logistic regression model
log.fit.weight4 <- glm(outcome ~ x.weight4, family="binomial")
#odds ratio
exp(summary(log.fit.weight4)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weight4)$coefficients[2]
se.beta <- summary(log.fit.weight4)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weight4)$coefficients[8]





#p.value < 10e-4
hit3 <- gwas.dt[p.value < 1e-3]
#columns of original table which come up as gwas significant
gdm.sig3.dt <- gdm.dt[, .SD, .SDcols = hit3$SNP.name]
#calculating the weighted score
weighted.score3.gwas <- as.matrix(gdm.sig3.dt) %*% hit3$reg.coeff
#adding the vector to the original data table
gdm.dt[, weighted3.scores := weighted.score3.gwas]
#x weighted scores
x.weight3 <- gdm.dt$weighted3.scores
#fit logistic regression model
log.fit.weight3 <- glm(outcome ~ x.weight3, family="binomial")
#odds ratio
exp(summary(log.fit.weight3)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weight3)$coefficients[2]
se.beta <- summary(log.fit.weight3)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weight3)$coefficients[8]




#FTO gene
hitfto <- gwas.dt[gene == "FTO"]
#columns of original table which come up as gwas significant
gdm.sigfto.dt <- gdm.dt[, .SD, .SDcols = hitfto$SNP.name]
#calculating the weighted score
weighted.scorefto.gwas <- as.matrix(gdm.sigfto.dt) %*% hitfto$reg.coeff
#adding the vector to the original data table
gdm.dt[, weightedFTO.scores := weighted.scorefto.gwas]
#x weighted score
x.weightfto <- gdm.dt$weightedFTO.scores
#fit logistic regression model
log.fit.weightfto <- glm(outcome ~ x.weightfto, family="binomial")
#odds ratio
exp(summary(log.fit.weightfto)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weightfto)$coefficients[2]
se.beta <- summary(log.fit.weightfto)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weightfto)$coefficients[8]

```


## (f)
```{r}
#read in the data
gdm.test.dt <- data.table(read.delim("GDM.test.txt"))

#columns of original table which come up as gwas significant
gdm.test.sig4.dt <- gdm.test.dt[, .SD, .SDcols = hit4$rsID]
#calculating the weighted score
weighted.test.score4.gwas <- as.matrix(gdm.test.sig4.dt) %*% hit4$reg.coeff
#adding the vector to the original data table
gdm.test.dt[, weighted4.scores := weighted.test.score4.gwas]
#outcome vector
outcome <- gdm.test.dt$pheno
#x weighted scores
x.weight4 <- gdm.test.dt$weighted4.scores
#fit logistic regression model
log.fit.weight4 <- glm(outcome ~ x.weight4, family="binomial")
#odds ratio
exp(summary(log.fit.weight4)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weight4)$coefficients[2]
se.beta <- summary(log.fit.weight4)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weight4)$coefficients[8]


#columns of original table which come up as gwas significant
gdm.test.sig3.dt <- gdm.test.dt[, .SD, .SDcols = hit3$rsID]
#calculating the weighted score
weighted.test.score3.gwas <- as.matrix(gdm.test.sig3.dt) %*% hit3$reg.coeff
#adding the vector to the original data table
gdm.test.dt[, weighted3.scores := weighted.test.score3.gwas]
#outcome vector
outcome <- gdm.test.dt$pheno
#x weighted scores
x.weight3 <- gdm.test.dt$weighted3.scores
#fit logistic regression model
log.fit.weight3 <- glm(outcome ~ x.weight3, family="binomial")
#odds ratio
exp(summary(log.fit.weight3)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weight3)$coefficients[2]
se.beta <- summary(log.fit.weight3)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weight3)$coefficients[8]



#columns of original table which come up as gwas significant
gdm.test.sigfto.dt <- gdm.test.dt[, .SD, .SDcols = hitfto$rsID]
#calculating the weighted score
weighted.test.scorefto.gwas <- as.matrix(gdm.test.sigfto.dt) %*% hitfto$reg.coeff
#adding the vector to the original data table
gdm.test.dt[, weightedfto.scores := weighted.test.scorefto.gwas]
#outcome vector
outcome <- gdm.test.dt$pheno
#x weighted scores
x.weightfto <- gdm.test.dt$weightedfto.scores
#fit logistic regression model
log.fit.weightfto <- glm(outcome ~ x.weightfto, family="binomial")
#odds ratio
exp(summary(log.fit.weightfto)$coefficients[2])
#95% confidence interval
beta <- summary(log.fit.weightfto)$coefficients[2]
se.beta <- summary(log.fit.weightfto)$coefficients[4]
round(exp(beta + 1.96 * se.beta * c(-1, 1)), 3)
#p value
summary(log.fit.weightfto)$coefficients[8]


```


## (g)
```{r}

```


## (h)
```{r}

```

# Problem 4
## (a)
```{r, warning=FALSE}
library(corrplot)

#load the data set
nki.dt <- data.table(read.csv("nki.csv"))

#separate genes from remainder of data
gen.nki.dt <- nki.dt[, c(7:76)]

#compute the correlation matrix
gen.corr <- cor(gen.nki.dt[, .SD, .SDcols = sapply(gen.nki.dt, is.numeric)])

#in order to adjust the writing size on the axis, a png file has to be safed
png(height=1200, width=1500, pointsize=15, file="overlap.png")
corrplot(gen.corr, diag = FALSE, method = "color", title = "NKI Correlation Matrix", order = "AOE", tl.col = "black", number.cex = 1)



```
The correlation matrix for dataset NKI is displayed below. If the image does not display correctly, please either find the saved image "overlay.png" or comment out the line starting with png(...) above (the adjusted font size will go missing)
![Correlation Matrix](overlap.png)

Identify the unique pairs of variables that have a correlation coefficient >0.8. My approach is based on the assumtion that no two correlation coefficients between two different variables are exactly equal. This assumption is reasonable since the correlation coefficients are recorded till the 8th significant figure which makes it highly unlikely that they would be the same.
```{r}
#create vectors for column and row names
r.nam <- row.names(gen.corr)
c.nam <- colnames(gen.corr)
#create vector that will hold the correlation coefficients that have been seen before
val.pair <- c()
#create opposite of %in%
`%notin%` <- Negate(`%in%`)

# Loop over gen.corr
for(row in 1:nrow(gen.corr)) {
    for(col in 1:ncol(gen.corr)) {
      #test if the correlation coefficient is greater than 0.8 (absolute)
      if(abs(gen.corr[row,col])>0.8){
        #test, if this is the correlation coefficient with itself
        if(row!=col){
          #test, if this correlation coefficient has been seen before
          if(gen.corr[row, col] %notin% val.pair){
            #print the results
            print(paste(r.nam[row], "and", c.nam[col], "have a correlation coefficient of",round(gen.corr[row, col],3)))
            #add the correlation coefficient to the list of correff, that have been seen before
            val.pair <- c(val.pair, gen.corr[row, col])
          }
        }
      }
    }
}

```
## (b)

Amount of variability explained by the first two principal components is 33%.
```{r}
#testing if elements are missing
stopifnot(is.na(gen.nki.dt)==0)

#run PCA
pca.gen <- prcomp(t(gen.nki.dt), scale=TRUE)

#Scatter plot
plot(pca.gen$x[, 1:2], main="Projection of variables on the first 2 PCs")


```

```{r}
#percentage of variance explained by the first two components
perc.expl.gen <- pca.gen$sdev^2 / sum(pca.gen$sdev^2)
sum(perc.expl.gen[1:2])

#Rule PA2<-10
#the 4 most different genes 
pca.gen$x[which(pca.gen$x[, 2]<(-10)), .SD]


```
## (c)
```{r}
#patient-wise PCA
pca.pats.gen <- prcomp(gen.nki.dt, scale=TRUE)

#Screeplot
screeplot(pca.pats.gen, main="Scree plot")

#keeping the first three principal components
three.pat.pca <- pca.pats.gen$x[,1:3]

#unadjusted logistic regression
#PCA 1
un.pca1 <- glm(nki.dt$Event ~ three.pat.pca[,1], family="binomial")
#PCA 2
un.pca2 <- glm(nki.dt$Event ~ three.pat.pca[,2], family="binomial")
#PCA 3
un.pca3 <- glm(nki.dt$Event ~ three.pat.pca[,3], family="binomial")

#adjusted logistic regression age, estrogen receptor, grade
#PCA 1
ad.pca1 <- glm(nki.dt$Event ~ three.pat.pca[,1]+ nki.dt$Age+ nki.dt$EstrogenReceptor + nki.dt$Grade, family="binomial")
#PCA 2
ad.pca2<- glm(nki.dt$Event ~ three.pat.pca[,2]+ nki.dt$Age+ nki.dt$EstrogenReceptor + nki.dt$Grade, family="binomial")
#PCA 3
ad.pca3 <- glm(nki.dt$Event ~ three.pat.pca[,3]+ nki.dt$Age+ nki.dt$EstrogenReceptor + nki.dt$Grade, family="binomial")
summary(ad.pca1)

```
## (d)

```{r}
#setting the seed
set.seed(1)

#separate the outcome and prepare dataset for lasso regression
ynki.dt <- as.matrix(nki.dt$Event)
xnki.dt <- prepare.glmnet(nki.dt, ~ . - Event)

#fit lasso regression
fit.cv.lasso <- cv.glmnet(xnki.dt, ynki.dt, family="binomial")

#running lasso regression only penalizing gene expression
#penalty = 1
#no penalty = 0
#preparing the penalty vector for lasso regression by setting the penalty for the first 5 columns (Diam-Age) to 0
pen <- rep(1, ncol(nki.dt[, !"Event"]))
pen[c(1:5)] <- 0

#lasso regression which only penalizes genes(does not run)
#pen.cv.lasso <- cv.glmnet(xnki.dt, ynki.dt, family="binomial", penalty.factor=pen)


```
